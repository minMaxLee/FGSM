{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1.  0.  0. ]\n",
      "  [0.  1.  0. ]]\n",
      "\n",
      " [[0.  0.  1. ]\n",
      "  [0.1 0.1 0.1]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD8CAYAAABZ0jAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFUlN/Q9CikfZbA/iLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6cbfe9e075ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# im = tf.convert_to_tensor([im])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "t = tf.constant([\n",
    "    [[1,0,0],[0,1,0]],\n",
    "    [[0,0,1],[0.1,0.1,0.1],]\n",
    "])\n",
    "\n",
    "print(t)\n",
    "plt.imshow(t)\n",
    "plt.show()\n",
    "\n",
    "t4 = tf.constant([\n",
    "    [[1.0,0,0],[.8,0,0],[0.6,0,0],[0.4,0,0]],\n",
    "    [[0,1,0],[0,0.8,0],[0,0.6,0],[0,0.4,0]],\n",
    "    [[0,0,1],[0,0,0.8],[0,0,0.6],[0,0,0.4]],\n",
    "    [[0.1,0.1,0.1],[0.1,0.1,0.1],[0.1,0.1,0.1],[0.1,0.1,0.1]]\n",
    "])\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "label = 5\n",
    "im = test_images[1]\n",
    "\n",
    "# im = tf.convert_to_tensor([im])\n",
    "pred = model(im)\n",
    "print(pred)\n",
    "\n",
    "label = tf.one_hot(label, 10)\n",
    "label = tf.reshape(label, (1,10))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(im)\n",
    "    prediction = model(im)\n",
    "    loss = loss_object(im, prediction)\n",
    "# Get the gradients of the loss w.r.t to the input image.\n",
    "gradient = tape.gradient(loss, im)\n",
    "# Get the sign of the gradients to create the perturbation\n",
    "signed_grad = tf.sign(gradient)\n",
    "\n",
    "print(signed_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f1de7a7efa71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axes.grid'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpl' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(include_top=True,\n",
    "                                                     weights='imagenet')\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "# need labels from CIFAR\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions\n",
    "\n",
    "def preprocess(image):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = tf.image.resize(image, (224, 224))\n",
    "  image = tf.keras.applications.mobilenet_v2.preprocess_input(image)\n",
    "  image = image[None, ...]\n",
    "  return image\n",
    "\n",
    "# Helper function to extract labels from probability vector\n",
    "def get_model_label(probs):\n",
    "  return decode_predictions(probs, top=1)[0][0]\n",
    "\n",
    "\n",
    "x = preprocess(x)\n",
    "x_prob = pretrained_model.predict(x)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(x[0]*0.5+0.5) # To change [-1, 1] to [0,1]\n",
    "# _, image_class, class_confidence = get_model_label(x_prob)\n",
    "# plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
    "# plt.show()\n",
    "# plt.imshow((x[0]*0.5 + 0.5) * 0.8)\n",
    "# plt.show()\n",
    "plt.figure(figsize=(10,10))\n",
    "ind = 1\n",
    "for i in range(3):\n",
    "    plt.subplot(3,2,ind)\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(\"l: {ind}\".format(ind = ind))\n",
    "    plt.subplot(3,2,ind+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(True)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(\"r:{ind}\".format(ind = ind+1))\n",
    "    ind += 2\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = 5\n",
    "im = test_images[1]\n",
    "\n",
    "# im = tf.convert_to_tensor([im])\n",
    "pred = model(im)\n",
    "print(pred)\n",
    "\n",
    "label = tf.one_hot(label, 10)\n",
    "label = tf.reshape(label, (1,10))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = model(input_image)\n",
    "        loss = loss_object(input_label, prediction)\n",
    "    # Get the gradients of the loss w.r.t to the input image.\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    # Get the sign of the gradients to create the perturbation\n",
    "    signed_grad = tf.sign(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = tf.keras.utils.get_file('YellowLabradorLooking_new.jpg', 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\n",
    "image_raw = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_image(image_raw)\n",
    "\n",
    "image = preprocess(image)\n",
    "image_probs = pretrained_model.predict(image)\n",
    "\n",
    "\n",
    "#shape of image: \n",
    "print(tf.shape(image))\n",
    "t = tf.tensor([0][0][0])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.imshow(image[0]*0.5+0.5) # To change [-1, 1] to [0,1]\n",
    "# _, image_class, class_confidence = get_model_label(image_probs)\n",
    "# plt.title('{} : {:.2f}% Confidence'.format(image_class, class_confidence*100))\n",
    "# plt.show()\n",
    "\n",
    "# x = tf.constant([[1],[2],[3]], tf.int32)\n",
    "# print(tf.shape(x))\n",
    "# x = tf.reshape(x,[3])\n",
    "# print(tf.shape(x))\n",
    "\n",
    "# # print(tf.shape(image_probs))\n",
    "\n",
    "\n",
    "# pred = pretrained_model(image)\n",
    "# # print(tf.shape(pred))\n",
    "# # print(tf.shape(image))\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "def create_adversarial_pattern(input_image, input_label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = pretrained_model(input_image)\n",
    "        loss = loss_object(input_label, prediction)\n",
    "        #     print(\"input label\", tf.shape(input_label))\n",
    "        #     print(\"pred:\" ,tf.shape(prediction))\n",
    "        print('loss', loss)\n",
    "        print('pred', prediction)\n",
    "\n",
    "    # Get the gradients of the loss w.r.t to the input image.\n",
    "    print('image:', input_image)\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    print(\"gradd:\", gradient)\n",
    "    # Get the sign of the gradients to create the perturbation\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad\n",
    "\n",
    "labrador_retriever_index = 208\n",
    "label = tf.one_hot(labrador_retriever_index, image_probs.shape[-1])\n",
    "label = tf.reshape(label, (1, image_probs.shape[-1]))\n",
    "\n",
    "perturbations = create_adversarial_pattern(image, label)\n",
    "print(perturbations)\n",
    "plt.imshow(perturbations[0]*0.5+0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
